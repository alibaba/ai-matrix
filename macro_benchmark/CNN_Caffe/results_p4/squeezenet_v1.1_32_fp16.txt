deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/squeezenet_v1.1_deploy.prototxt
output: prob
batch: 32
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/squeezenet_v1.1.caffemodel
half2
Input "data": 3x227x227
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 9.96143 ms.
Average over 10 runs is 9.95894 ms.
Average over 10 runs is 9.96442 ms.
Average over 10 runs is 9.96137 ms.
Average over 10 runs is 9.9677 ms.
Average over 10 runs is 9.96418 ms.
Average over 10 runs is 9.95321 ms.
Average over 10 runs is 9.95929 ms.
Average over 10 runs is 9.96258 ms.
Average over 10 runs is 9.94395 ms.
