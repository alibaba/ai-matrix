deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/resnet152_deploy.prototxt
output: prob
batch: 16
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/resnet152.caffemodel
half2
Input "data": 3x224x224
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 86.7529 ms.
Average over 10 runs is 86.8988 ms.
Average over 10 runs is 86.9259 ms.
Average over 10 runs is 86.5856 ms.
Average over 10 runs is 87.2306 ms.
Average over 10 runs is 87.4836 ms.
Average over 10 runs is 86.6627 ms.
Average over 10 runs is 86.8165 ms.
Average over 10 runs is 87.4556 ms.
Average over 10 runs is 86.8187 ms.
