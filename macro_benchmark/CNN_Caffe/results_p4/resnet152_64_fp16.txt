deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/resnet152_deploy.prototxt
output: prob
batch: 64
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/resnet152.caffemodel
half2
Input "data": 3x224x224
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 322.496 ms.
Average over 10 runs is 323.515 ms.
Average over 10 runs is 324.576 ms.
Average over 10 runs is 324.262 ms.
Average over 10 runs is 327.054 ms.
Average over 10 runs is 325.036 ms.
Average over 10 runs is 326.195 ms.
Average over 10 runs is 326.495 ms.
Average over 10 runs is 328.134 ms.
Average over 10 runs is 327.009 ms.
