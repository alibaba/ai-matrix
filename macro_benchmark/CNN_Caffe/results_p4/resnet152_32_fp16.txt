deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/resnet152_deploy.prototxt
output: prob
batch: 32
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/resnet152.caffemodel
half2
Input "data": 3x224x224
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 169.064 ms.
Average over 10 runs is 170.304 ms.
Average over 10 runs is 169.768 ms.
Average over 10 runs is 170.003 ms.
Average over 10 runs is 169.294 ms.
Average over 10 runs is 169.311 ms.
Average over 10 runs is 169.312 ms.
Average over 10 runs is 169.848 ms.
Average over 10 runs is 171.993 ms.
Average over 10 runs is 170.638 ms.
