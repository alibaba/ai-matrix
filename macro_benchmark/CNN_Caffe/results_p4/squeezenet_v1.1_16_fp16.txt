deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/squeezenet_v1.1_deploy.prototxt
output: prob
batch: 16
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/squeezenet_v1.1.caffemodel
half2
Input "data": 3x227x227
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 5.35533 ms.
Average over 10 runs is 5.33968 ms.
Average over 10 runs is 5.34457 ms.
Average over 10 runs is 5.33629 ms.
Average over 10 runs is 5.33195 ms.
Average over 10 runs is 5.33618 ms.
Average over 10 runs is 5.32484 ms.
Average over 10 runs is 5.33488 ms.
Average over 10 runs is 5.33505 ms.
Average over 10 runs is 5.33514 ms.
