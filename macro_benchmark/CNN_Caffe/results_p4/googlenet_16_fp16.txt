deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/googlenet_deploy.prototxt
output: prob
batch: 16
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/googlenet_iter_500.caffemodel
half2
Input "data": 3x224x224
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 15.0116 ms.
Average over 10 runs is 15.0154 ms.
Average over 10 runs is 14.9866 ms.
Average over 10 runs is 15.0163 ms.
Average over 10 runs is 15.0136 ms.
Average over 10 runs is 15.0242 ms.
Average over 10 runs is 15.0233 ms.
Average over 10 runs is 15.0088 ms.
Average over 10 runs is 14.9993 ms.
Average over 10 runs is 15.021 ms.
