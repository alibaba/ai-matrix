deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/squeezenet_v1.1_deploy.prototxt
output: prob
batch: 64
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/squeezenet_v1.1.caffemodel
half2
Input "data": 3x227x227
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 19.2612 ms.
Average over 10 runs is 19.268 ms.
Average over 10 runs is 19.2576 ms.
Average over 10 runs is 19.2836 ms.
Average over 10 runs is 19.2763 ms.
Average over 10 runs is 19.2734 ms.
Average over 10 runs is 19.268 ms.
Average over 10 runs is 19.2562 ms.
Average over 10 runs is 19.2576 ms.
Average over 10 runs is 19.2554 ms.
