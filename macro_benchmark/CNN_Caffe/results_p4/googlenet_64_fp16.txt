deploy: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/googlenet_deploy.prototxt
output: prob
batch: 64
device: 1
model: /home/weiwei/AIMatrix/macro_benchmark/caffe_inference/googlenet_iter_500.caffemodel
half2
Input "data": 3x224x224
Output "prob": 1000x1x1
Half2 support requested on hardware without native FP16 support, performance will be negatively affected.
name=data, bindingIndex=0, buffers.size()=2
name=prob, bindingIndex=1, buffers.size()=2
Average over 10 runs is 54.7523 ms.
Average over 10 runs is 55.2984 ms.
Average over 10 runs is 55.1421 ms.
Average over 10 runs is 55.0551 ms.
Average over 10 runs is 54.8926 ms.
Average over 10 runs is 55.1366 ms.
Average over 10 runs is 55.2337 ms.
Average over 10 runs is 55.226 ms.
Average over 10 runs is 55.119 ms.
Average over 10 runs is 55.2872 ms.
